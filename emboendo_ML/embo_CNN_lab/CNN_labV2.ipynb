{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERNEL CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f -s\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import CNN_lib\n",
    "import CNN_utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_type='processed'     # 'processed', 'synthetic'\n",
    "video_d=True            # Video = True , Image = False \n",
    "test_data,number_data_points= False,500\n",
    "\n",
    "checkpoint_path = \"C:/PROJECTS\\emboendo\\CNN\\python-machine-learning\\emboendo_ML\\embo_CNN_lab\\_static/model_checkpoint.h5\"\n",
    "\n",
    "if d_type=='processed' : pkl_train_p='C:\\PROJECTS\\emboendo\\CNN/pikles/processed_train_d.pkl'  \n",
    "elif d_type=='synthetic' : pkl_train_p='C:\\PROJECTS\\emboendo\\CNN/pikles/synthetic_train_d.pkl'   \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,Y_train\n",
    "\n",
    "with open(pkl_train_p, 'rb') as pikle_file:\n",
    "\n",
    "    save_trains= pickle.load(pikle_file)\n",
    "\n",
    "x_train,y_train =  save_trains[0],save_trains[1]\n",
    "\n",
    "max_frm_n, HEIGHT, WIDTH=np.shape(x_train)[1],np.shape(x_train)[2],np.shape(x_train)[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data:\n",
    "\n",
    "    total_data_points=len(y_train)\n",
    "    test_len=total_data_points-number_data_points\n",
    "    \n",
    "    Xx_train=x_train[0:number_data_points]\n",
    "    Yy_train=y_train[0:number_data_points]\n",
    "\n",
    "else:\n",
    "\n",
    "    Xx_train=x_train\n",
    "    Yy_train=y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,Y_train,X_eval,Y_eval\n",
    "\n",
    "test_size=0.2\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split(Xx_train, Yy_train, test_size=test_size) #,random_state=42)\n",
    "\n",
    "print('Train data:',len(Y_train),'Evaluation data:',len(Y_eval))\n",
    "if test_data:print('Test_len:',test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "\n",
    "zeros_count = np.sum(Y_train == 0)\n",
    "ones_count = np.sum(Y_train == 1)\n",
    "zeros_count_val = np.sum(Y_eval == 0)\n",
    "ones_count_val = np.sum(Y_eval == 1)\n",
    "\n",
    "labels = ['0 Train', '1 Train','0 Validation', '1 Validation']\n",
    "print(' Train data shape:', np.shape(X_train),' Validation data shape:', np.shape(X_eval))\n",
    "\n",
    "plt.bar(labels, [zeros_count, ones_count,zeros_count_val,ones_count_val], color=['green', 'blue','green', 'blue'])\n",
    "\n",
    "for i, count in enumerate([zeros_count, ones_count,zeros_count_val,ones_count_val]):\n",
    "\n",
    "    plt.text(i, count + 0.1, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Data Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LIBRARY MODELS:')\n",
    "print(' ')\n",
    "\n",
    "for model_name in CNN_lib.MODELS.values(): print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CNN PARAMS --------\n",
    "\n",
    "# -------- MODEL --------\n",
    "\n",
    "model_from_CNN_lib,mdl= False,'video_conv3D'\n",
    "\n",
    "opt='adam'\n",
    "lss='binary_crossentropy'\n",
    "\n",
    "# -------- TRAINNING --------\n",
    "\n",
    "epch=4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL \n",
    "\n",
    "if model_from_CNN_lib:\n",
    "  \n",
    "  if video_d: model = CNN_lib.lib_models(mdl,im_input_shp=(max_frm_n, HEIGHT, WIDTH, 1))\n",
    "  else: model = CNN_lib.lib_models(mdl,im_input_shp=(HEIGHT, WIDTH,1))\n",
    "\n",
    "else:\n",
    "\n",
    "  model = models.Sequential([\n",
    "          layers.Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu',input_shape=(max_frm_n, HEIGHT, WIDTH, 1)),\n",
    "          layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "          layers.Conv3D(filters=32, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "          layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "          layers.Conv3D(filters=32, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "          layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "          layers.Conv3D(filters=64, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "          layers.Flatten(),\n",
    "          layers.Dropout(0.2),\n",
    "          layers.Dense(64, activation='relu'),\n",
    "          layers.Dropout(0.2),\n",
    "          layers.Dense(64, activation='relu'),\n",
    "          layers.Dropout(0.2),\n",
    "          layers.Dense(64, activation='relu'),\n",
    "          layers.Dropout(0.2),\n",
    "          layers.Dense(32, activation='relu'),\n",
    "          layers.Dense(1,activation='sigmoid')\n",
    "          ])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=lss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss',   mode='min', verbose=1)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history =model.fit(X_train, Y_train, epochs=epch, validation_data=(X_eval,Y_eval),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_size=(14,8)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epch)\n",
    "\n",
    "plt.figure(figsize=fg_size)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')  \n",
    "plt.ylabel('Accuracy')  \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range[1:-1], loss[1:-1], label='Training Loss')\n",
    "plt.plot(epochs_range[1:-1], val_loss[1:-1], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_eval,Y_eval,verbose=2)\n",
    "\n",
    "print(f'Loss: {test_loss}',f'Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(checkpoint_path)\n",
    "test_loss, test_accuracy = model.evaluate(X_eval,Y_eval,verbose=2)\n",
    "print(f'Loss: {test_loss}',f'Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_d={'NAME':mdl,\n",
    "               'ACCURACY':test_accuracy,\n",
    "               'LOSS':test_loss,\n",
    "               'HEIGHT':HEIGHT,\n",
    "               'WIDTH':WIDTH}\n",
    "\n",
    "performance_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC CURVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_eval, Y_train, Y_eval \n",
    "\n",
    "\n",
    "fpr_val, tpr_val, thresholds_val = roc_curve(Y_eval, model.predict(X_eval))\n",
    "\n",
    "\n",
    "roc_auc_val = auc(fpr_val, tpr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr_val, tpr_val, color='darkorange', lw=2, label=f'AUC = {roc_auc_val:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Validation Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data:\n",
    "    \n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_train[number_data_points+1:-1], model.predict(x_train[number_data_points+1:-1]))\n",
    "\n",
    "\n",
    "    roc_auc = auc(fpr_test, tpr_test)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr_test, tpr_test, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve Testing Data')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  FORECAST EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 684ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(X_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]],\n",
       "\n",
       "\n",
       "       [[[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]],\n",
       "\n",
       "\n",
       "       [[[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]],\n",
       "\n",
       "\n",
       "       [[[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]],\n",
       "\n",
       "\n",
       "       [[[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "true_classes = Y_eval  \n",
    "\n",
    "correctly_classified_indices = np.where(predicted_classes == true_classes)[0]\n",
    "incorrectly_classified_indices = np.where(predicted_classes != true_classes)[0]\n",
    "\n",
    "correctly_classified_video_ids = [video_id for video_id in correctly_classified_indices]\n",
    "incorrectly_classified_video_ids = [video_id for video_id in incorrectly_classified_indices]\n",
    "\n",
    "num_zeros = np.count_nonzero(Y_eval == 0)\n",
    "num_ones = np.count_nonzero(Y_eval == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels_val = [Y_eval[i] for i in correctly_classified_indices]\n",
    "print(correct_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"OK, {len(correctly_classified_video_ids)}\")\n",
    "print(f\"BAD, {len(incorrectly_classified_video_ids)}\")\n",
    "print(f'Ratio forecast: {len(correctly_classified_video_ids)/len(incorrectly_classified_video_ids)}')\n",
    "print(f'Ratio labeling: {max([num_ones,num_zeros])/min([num_ones,num_zeros])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.23231651]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevo_video = np.expand_dims(X_eval[9], axis=0)\n",
    "\n",
    "# Realizar la predicci√≥n\n",
    "prediccion = model.predict(nuevo_video)\n",
    "prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
