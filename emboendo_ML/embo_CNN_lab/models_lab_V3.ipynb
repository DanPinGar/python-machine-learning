{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import fig_lib \n",
    "import CNN_lib\n",
    "import CNN_utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18360024797699070600\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p\n",
    "pkl_d_p = 'C:\\PROJECTS\\emboendo\\CNN/input_d.pkl'\n",
    "pkl_train_p='C:\\PROJECTS\\emboendo\\CNN/train_d.pkl'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- PROCESS DICOM DATA --------------\n",
    "\n",
    "data_load_dicom,generate_new_peakle=True,True\n",
    "\n",
    "max_frames_allowed=40\n",
    "\n",
    "# ------- GENERATE SYNTHETIC DATA --------------\n",
    "\n",
    "generate_new_data=False \n",
    "\n",
    "\n",
    "# --------- LOAD TRAN DATA ------------\n",
    "\n",
    "load_train_data=False\n",
    "\n",
    "# --------- DATA TYPE ------------\n",
    "video_d=True                                    # Video = True , Image = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if data_load_dicom:\n",
    "\n",
    "    patients_recs_d_df=CNN_utilities.main_d_df()\n",
    "    patients_labels_d_df=CNN_utilities.labels_df()\n",
    "    patients_d_df=pd.merge( patients_labels_d_df,patients_recs_d_df, on='PatientID')\n",
    "    \n",
    "\n",
    "    tot_recs=sum(len(records) for records in patients_d_df[\"Records\"])\n",
    "    filtered_df_0,filtered_df_1 = patients_d_df[patients_d_df['label'] == 0],patients_d_df[patients_d_df['label'] == 1]\n",
    "    label_0,label_1 = sum(len(records) for records in filtered_df_0['Records']),sum(len(records) for records in filtered_df_1['Records'])\n",
    "\n",
    "    print(f'- PATIENTS: {patients_d_df.shape[0]} ,PATIENT LABEL 0: {sum(patients_d_df[\"label\"]==0)}, PATIENT LABEL 1: {sum(patients_d_df[\"label\"]==1)}')\n",
    "    print( f'- RECORDS: {tot_recs} , RECORDS LABEL 0: {label_0}, RECORDS LABEL 1:{label_1}')\n",
    "    print(f'- RATIO LABEL 0: {np.round(label_0/sum(patients_d_df[\"label\"]==0),decimals=2)}, RATIO LABEL 1: {np.round(label_1/sum(patients_d_df[\"label\"]==1),decimals=2)}')\n",
    "\n",
    "    display(patients_d_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if data_load_dicom:\n",
    "    \n",
    "    if generate_new_peakle:\n",
    "        \n",
    "        input_d={}    \n",
    "\n",
    "        for label,ii in zip(patients_d_df['label'],patients_d_df['Records']):\n",
    "            \n",
    "            for rec in ii:\n",
    "\n",
    "                input_d[rec]={'label':label}\n",
    "                ds_file=CNN_utilities.load_rec(rec)\n",
    "                vd_ls=[]\n",
    "\n",
    "                for i in range(ds_file.pixel_array.shape[0]):\n",
    "                    \n",
    "                    if i== max_frames_allowed: break\n",
    "                    else:\n",
    "                        image_8bit,  width, height = CNN_utilities.im_data(ds_file.pixel_array[i])\n",
    "                        vd_ls.append(image_8bit)\n",
    "                    \n",
    "\n",
    "                input_d[rec]['image']=np.array(vd_ls)\n",
    "                input_d[rec]['dimHW']= [height,width]   \n",
    "\n",
    "        with open(pkl_d_p, 'wb') as pikle_file:\n",
    "            pickle.dump(input_d, pikle_file)\n",
    "        \n",
    "\n",
    "    else: \n",
    "\n",
    "        with open(pkl_d_p, 'rb') as pikle_file:\n",
    "            input_d = pickle.load(pikle_file)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_load_dicom:    \n",
    "    \n",
    "    print('FIRST LAYER KEYS:', list(input_d.keys()))\n",
    "    print('SECOND LAYER KEYS:',list(input_d[list(input_d.keys())[0]].keys()))\n",
    "    print(f' KEY TYPE \"{list(input_d[list(input_d.keys())[0]].keys())[0]}\":',type(input_d[list(input_d.keys())[0]][list(input_d[list(input_d.keys())[0]].keys())[0]]),'Example:',input_d[list(input_d.keys())[0]][list(input_d[list(input_d.keys())[0]].keys())[0]])\n",
    "    print(f' KEY TYPE \"{list(input_d[list(input_d.keys())[0]].keys())[1]}\":',type(input_d[list(input_d.keys())[0]][list(input_d[list(input_d.keys())[1]].keys())[1]]),'Example shape:',np.shape(input_d[list(input_d.keys())[0]][list(input_d[list(input_d.keys())[1]].keys())[1]]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_load_dicom:\n",
    "    print('RECORD - LABEL - SHAPE')\n",
    "\n",
    "    for R in input_d.keys():\n",
    "        print(R,input_d[R]['label'],np.shape(input_d[R]['image']),type(input_d[R]['image']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- DATA PARAMS --------               \n",
    "\n",
    "if generate_new_data:    \n",
    "\n",
    "    total_n_recs=400\n",
    "    #n_recs_train,n_recs_eval=300,80\n",
    "    HEIGHT, WIDTH = 100, 100\n",
    "    circles_filled=False\n",
    "    color=255\n",
    "\n",
    "    # -------- Video ---------\n",
    " \n",
    "\n",
    "    n_frames=[10,12]    # [min,max]\n",
    "\n",
    "    t_btw_frm=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_d, eval_d\n",
    "\n",
    "if generate_new_data:\n",
    "\n",
    "    if video_d:\n",
    "        \n",
    "        input_d=fig_lib.vid_data_gen(HEIGHT, WIDTH,total_n_recs,n_frames,'I',cir_f=circles_filled,color=color)\n",
    "        \n",
    "    else:\n",
    "\n",
    "        input_d=fig_lib.im_data_gen(HEIGHT, WIDTH,total_n_recs,'I',cir_f=circles_filled,color=color)\n",
    "\n",
    "    print('FIRST LAYER KEYS:', list(input_d.keys()))\n",
    "    print('SECOND LAYER KEYS:',list(input_d[list(input_d.keys())[0]].keys()))\n",
    "    print(f' KEY TYPE \"{list(input_d[list(input_d.keys())[0]].keys())[0]}\":',type(input_d[list(input_d.keys())[0]][list(input_d[list(input_d.keys())[0]].keys())[0]]),'Example:',input_d[list(input_d.keys())[0]][list(input_d[list(input_d.keys())[0]].keys())[0]])\n",
    "    print(f' KEY TYPE \"{list(input_d[list(input_d.keys())[0]].keys())[1]}\":',type(input_d[list(input_d.keys())[0]][list(input_d[list(input_d.keys())[1]].keys())[1]]),'Example shape:',np.shape(input_d[list(input_d.keys())[0]][list(input_d[list(input_d.keys())[1]].keys())[1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RECORD - LABEL - SHAPE')\n",
    "\n",
    "if generate_new_data:\n",
    "    \n",
    "    for R in input_d.keys():\n",
    "        print(R,input_d[R]['label'],np.shape(input_d[R]['image']),type(input_d[R]['image']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_btw_frm=0.05\n",
    "d_plt_check,rec_check=False,'I0'\n",
    "print(input_d[rec_check]['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check video\n",
    "\n",
    "if d_plt_check:\n",
    "\n",
    "    if video_d:fig_lib.vid_show(input_d[rec_check]['image'],t_btw_frm=t_btw_frm)\n",
    "    else:fig_lib.im_show(input_d[rec_check]['image'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,Y_train\n",
    "\n",
    "if load_train_data: \n",
    "      \n",
    "    with open(pkl_train_p, 'rb') as pikle_file:\n",
    "\n",
    "        save_trains= pickle.load(pikle_file)\n",
    "\n",
    "    X_train,Y_train =  save_trains[0],save_trains[1]\n",
    "\n",
    "else:\n",
    "\n",
    "    if video_d:X_train,Y_train,max_frm_n,HEIGHT, WIDTH =CNN_lib.vid_d_bin_gen(input_d, zero=0, one= 1)\n",
    "    else:X_train,Y_train =CNN_lib.im_d_bin_gen(input_d,zero='circle', one= 'line')\n",
    "\n",
    "    save_trains=[X_train,Y_train]\n",
    "\n",
    "    with open(pkl_train_p, 'wb') as pikle_file:\n",
    "            \n",
    "            pickle.dump(save_trains, pikle_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,Y_train,X_eval,Y_eval\n",
    "\n",
    "test_size=0.2\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split(X_train, Y_train, test_size=test_size) #,random_state=42)\n",
    "\n",
    "print('Train data:',len(Y_train),'Evaluation data:',len(Y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "\n",
    "zeros_count = np.sum(Y_train == 0)\n",
    "ones_count = np.sum(Y_train == 1)\n",
    "zeros_count_val = np.sum(Y_eval == 0)\n",
    "ones_count_val = np.sum(Y_eval == 1)\n",
    "\n",
    "labels = ['Circles Train', 'Lines Train','Circles Validation', 'Lines Validation']\n",
    "print(' Train data shape:', np.shape(X_train),' Validation data shape:', np.shape(X_eval))\n",
    "\n",
    "plt.bar(labels, [zeros_count, ones_count,zeros_count_val,ones_count_val], color=['green', 'blue','green', 'blue'])\n",
    "\n",
    "for i, count in enumerate([zeros_count, ones_count,zeros_count_val,ones_count_val]):\n",
    "\n",
    "    plt.text(i, count + 0.1, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Data Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "process_time = end_time - init_time\n",
    "print(f\"Tiempo transcurrido: {process_time} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LIBRARY MODELS:')\n",
    "print(' ')\n",
    "\n",
    "for model_name in CNN_lib.MODELS.values(): print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CNN PARAMS --------\n",
    "\n",
    "# -------- MODEL --------\n",
    "\n",
    "model_from_CNN_lib,mdl= False,'video_conv2D'\n",
    "\n",
    "opt='adam'\n",
    "lss='binary_crossentropy'\n",
    "\n",
    "# -------- TRAINNING --------\n",
    "\n",
    "epch=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL \n",
    "\n",
    "if model_from_CNN_lib:\n",
    "  \n",
    "  if video_d: model = CNN_lib.lib_models(mdl,im_input_shp=(max_frm_n, HEIGHT, WIDTH, 1))\n",
    "  else: model = CNN_lib.lib_models(mdl,im_input_shp=(HEIGHT, WIDTH,1))\n",
    "\n",
    "else:\n",
    "\n",
    "  model = models.Sequential([\n",
    "          layers.Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu',input_shape=(max_frm_n, HEIGHT, WIDTH, 1)),\n",
    "          layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "          layers.Conv3D(filters=32, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "          layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "          layers.Conv3D(filters=32, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "          layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "          layers.Conv3D(filters=64, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(64, activation='relu'),\n",
    "          layers.Dense(1,activation='sigmoid')\n",
    "          ])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=lss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history =model.fit(X_train, Y_train, epochs=epch, validation_data=(X_eval,Y_eval))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_size=(14,8)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epch)\n",
    "\n",
    "plt.figure(figsize=fg_size)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')  \n",
    "plt.ylabel('Accuracy')  \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_eval,Y_eval,verbose=2)\n",
    "\n",
    "print(f'Loss: {test_loss}',f'Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_d={'NAME':mdl,\n",
    "               'ACCURACY':test_accuracy,\n",
    "               'LOSS':test_loss,\n",
    "               'VIDEO':video_d,\n",
    "               'TRAIN SAMPLES':n_recs_train,\n",
    "               'VALIDATION SAMPLES':n_recs_eval,\n",
    "               'TRAINNING TIME':t_train,\n",
    "               'EPOCHS':epch,\n",
    "               'FRAMES RANGE':n_frames,\n",
    "               'HEIGHT':HEIGHT,\n",
    "               'WIDTH':WIDTH}\n",
    "\n",
    "performance_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORECAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE RANDOM IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random im\n",
    "\n",
    "n_rdm=np.random.rand()\n",
    "\n",
    "if video_d:\n",
    "    \n",
    "    vd_ls=[]\n",
    "    N_frames=np.random.randint(n_frames[0],n_frames[1]+1)\n",
    "\n",
    "    if n_rdm>=0.5:\n",
    "\n",
    "        p1=[np.random.randint(0, WIDTH-1),np.random.randint(0, HEIGHT-1)]\n",
    "        p2=[np.random.randint(0, WIDTH-1),np.random.randint(0, HEIGHT-1)]\n",
    "\n",
    "        for _ in range(N_frames):\n",
    "\n",
    "            vd_ls.append(fig_lib.line_im(p1,p2,height=HEIGHT, width=WIDTH,thickness=(1,3),color=color))\n",
    "            p1[0]+= np.random.randint(-int(WIDTH*0.02), int(WIDTH*0.02))\n",
    "            p2[0]+=np.random.randint(-int(WIDTH*0.06), int(WIDTH*0.06))\n",
    "            p1[1]+= np.random.randint(-int(HEIGHT*0.02), int(HEIGHT*0.02))\n",
    "            p2[1]+=np.random.randint(-int(HEIGHT*0.06), int(HEIGHT*0.06))\n",
    "\n",
    "        label='Line'\n",
    "        \n",
    "\n",
    "    else:\n",
    "\n",
    "        center= [np.random.randint(int(0+WIDTH*0.3), int(WIDTH - WIDTH*0.3)),np.random.randint(int(0+HEIGHT*0.3), int(HEIGHT-HEIGHT*0.3))]\n",
    "        radio = np.random.randint(12, 17)\n",
    "\n",
    "        for _ in range(N_frames):\n",
    "        \n",
    "            vd_ls.append(fig_lib.circle_im(center,radio,height=HEIGHT, width=WIDTH,thickness=(1,3),color=color,filled=circles_filled))\n",
    "            center[0]+= np.random.randint(-int(WIDTH*0.03), int(WIDTH*0.03))\n",
    "            center[1]+= np.random.randint(-int(HEIGHT*0.03), int(HEIGHT*0.03))\n",
    "            radio += np.random.randint(-int(HEIGHT*0.01), int(HEIGHT*0.02))\n",
    "\n",
    "        label ='circle'\n",
    "\n",
    "    video=np.array(vd_ls)\n",
    "    image = video[:, :, :, np.newaxis]\n",
    "    frames_actual = image.shape[0]\n",
    "    if frames_actual < max_frm_n:\n",
    "        \n",
    "        padding = np.zeros((max_frm_n - frames_actual, HEIGHT, WIDTH, 1))\n",
    "        image = np.concatenate([image, padding], axis=0)\n",
    "\n",
    "else:\n",
    "\n",
    "    if n_rdm>=0.5:\n",
    "\n",
    "        p1=[np.random.randint(0, WIDTH-1),np.random.randint(0, HEIGHT-1)]\n",
    "        p2=[np.random.randint(0, WIDTH-1),np.random.randint(0, HEIGHT-1)]\n",
    "        image=fig_lib.line_im(p1,p2,height=HEIGHT, width=WIDTH,thickness=(1,3),color=color)\n",
    "        label='Line'\n",
    "\n",
    "    else:\n",
    "        \n",
    "        center= [np.random.randint(int(0+WIDTH*0.3), int(WIDTH - WIDTH*0.3)),np.random.randint(int(0+HEIGHT*0.3), int(HEIGHT-HEIGHT*0.3))]\n",
    "        radio = np.random.randint(12, 17)\n",
    "        image=fig_lib.circle_im(center,radio,height=HEIGHT, width=WIDTH,thickness=(1,3),color=color,filled=circles_filled)\n",
    "        label= 'circle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "\n",
    "pred = model.predict(np.expand_dims(image, axis=0),verbose=2)\n",
    "CNN_lib.bin_forecast(pred,label=label,up_frc='line',down_frc='circle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "\n",
    "if video_d:fig_lib.vid_show(video)\n",
    "else:fig_lib.im_show(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
