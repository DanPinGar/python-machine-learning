{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\PROJECTS\\EMBOENDO\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import CNN_lib\n",
    "import CNN_utilities\n",
    "import fig_lib \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_n=12\n",
    "\n",
    "data_split='rnd_patients'                                # 'rnd_recs' 'rnd_patients'\n",
    "\n",
    "checking_on=False\n",
    "t_btw_frm=0.05\n",
    "check_record_1= '670615_19'\n",
    "check_record_2= 'ROT_670615_19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- MODEL --------\n",
    "\n",
    "mdl = 'Test E'\n",
    "opt='adam'\n",
    "lss='binary_crossentropy'\n",
    "\n",
    "# -------- TRAINNING --------\n",
    "\n",
    "epochs=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_split == 'rnd_recs': test_size=0.2           \n",
    "\n",
    "elif data_split == 'rnd_patients': val_pat_0,val_pat_1 = 11 , 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flip_1,n_flip_0=0.7 , 0.07\n",
    "\n",
    "n_rot_1,n_rot_0=0.6 , 0.06\n",
    "\n",
    "n_contr_1,n_contr_0=0.4 , 0.04\n",
    "\n",
    "n_bright_1,n_bright_0=0.3 , 0.03\n",
    "\n",
    "aug_params={'f1':n_flip_1,'f0':n_flip_0,'r1':n_rot_1,'r0':n_rot_0,'c1':n_contr_1,'c0':n_contr_0,'b1':n_bright_1,'b0':n_bright_0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"C:/PROJECTS\\emboendo\\CNN\\python-machine-learning\\emboendo_ML\\embo_CNN_lab\\_static/checkpoints\"\n",
    "pkl_train_p='C:\\PROJECTS\\emboendo\\CNN/pikles/processed_train_d.pkl'   \n",
    "check_points_p = [checkpoint_path+'_'+str(n)+'.h5' for n in range(trains_n)]\n",
    "\n",
    "if data_split == 'rnd_patients': json_fix_sq_p='C:\\PROJECTS\\emboendo\\dicom_viewer\\_static\\Jsons\\points_fix_d.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_split == 'rnd_patients':\n",
    "\n",
    "    with open(json_fix_sq_p, 'r') as json_file:\n",
    "        json_d = json.load(json_file)\n",
    "\n",
    "    patients_d_df =  CNN_utilities.gen_patients_d_df(json_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_train_p, 'rb') as pikle_file:\n",
    "\n",
    "    save_trains= pickle.load(pikle_file)\n",
    "\n",
    "x_train,y_train,rcs =  save_trains[0],save_trains[1],save_trains[2]\n",
    "\n",
    "max_frm_n, HEIGHT, WIDTH=np.shape(x_train)[1],np.shape(x_train)[2],np.shape(x_train)[3]\n",
    "input_shape=(max_frm_n, HEIGHT, WIDTH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\PROJECTS\\EMBOENDO\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\PROJECTS\\EMBOENDO\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_55 (Conv3D)          (None, 40, 158, 158, 16   160       \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_55 (MaxPooli  (None, 40, 79, 79, 16)    0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_56 (Conv3D)          (None, 40, 77, 77, 32)    4640      \n",
      "                                                                 \n",
      " max_pooling3d_56 (MaxPooli  (None, 40, 38, 38, 32)    0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_57 (Conv3D)          (None, 40, 36, 36, 32)    9248      \n",
      "                                                                 \n",
      " max_pooling3d_57 (MaxPooli  (None, 40, 18, 18, 32)    0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_58 (Conv3D)          (None, 40, 16, 16, 32)    9248      \n",
      "                                                                 \n",
      " max_pooling3d_58 (MaxPooli  (None, 20, 8, 8, 32)      0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_59 (Conv3D)          (None, 10, 8, 8, 32)      11296     \n",
      "                                                                 \n",
      " max_pooling3d_59 (MaxPooli  (None, 5, 4, 4, 32)       0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 2560)              0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                163904    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200609 (783.63 KB)\n",
      "Trainable params: 200609 (783.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(max_frm_n, HEIGHT, WIDTH, 1)\n",
    "\n",
    "modelos=[]\n",
    "\n",
    "for _ in check_points_p:\n",
    "\n",
    "  model = models.Sequential([\n",
    "            layers.Conv3D(filters=16, kernel_size=(1, 3, 3), activation='relu',input_shape=input_shape),\n",
    "            layers.MaxPooling3D(pool_size=(1, 2, 2)),\n",
    "            layers.Conv3D(filters=32, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "            layers.MaxPooling3D(pool_size=(1, 2, 2)),\n",
    "            layers.Conv3D(filters=32, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "            layers.MaxPooling3D(pool_size=(1, 2, 2)),\n",
    "            layers.Conv3D(filters=32, kernel_size=(1, 3, 3),  activation='relu'),\n",
    "            layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "            layers.Conv3D(filters=32, kernel_size=(11, 1, 1),  activation='relu'),\n",
    "            layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "    \n",
    "  model.compile(optimizer=opt, loss=lss, metrics=['accuracy'])\n",
    "  modelos.append(model)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints=[ModelCheckpoint(pp, save_best_only=True, monitor='val_loss',   mode='min', verbose=1) for pp in check_points_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA INPUT CHECK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on:\n",
    "\n",
    "    for x,y,r in zip(x_train,y_train,rcs):print(r,int(y),np.shape(x),type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on: CNN_utilities.simple_check(check_record_1,rcs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN TRAINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter=0\n",
    "histories=[]\n",
    "\n",
    "for md, chk_p in zip(modelos,checkpoints):\n",
    "\n",
    "    X_d,Y_d,recs=CNN_lib.shuffle(x_train,y_train,rcs)                                                                                                                                                      # SHUFFLE\n",
    "\n",
    "    if data_split=='rnd_recs': X_train_spl, X_eval_spl, Y_train_spl, Y_eval_spl ,recs_train,recs_eval=CNN_utilities.random_split_by_recs(X_d, Y_d,recs, test_size=test_size)                               # SPLIT\n",
    "    else: X_train_spl, X_eval_spl, Y_train_spl, Y_eval_spl ,recs_train,recs_eval=CNN_utilities.random_split_by_patients(patients_d_df,recs,X_d,Y_d, val_pat_0=val_pat_0, val_pat_1=val_pat_1)\n",
    "\n",
    "    X_eval,Y_eval=X_eval_spl,Y_eval_spl\n",
    "\n",
    "    if checking_on: CNN_utilities.in_loop_check(check_record_1,recs_train,X_train_spl,Y_train_spl)                                                                                                            # CHECK\n",
    "\n",
    "    X_train_spl, Y_train_spl, recs_train = CNN_lib.d_augmentation_logic_encapsulation(X_train_spl,Y_train_spl,recs_train,aug_params)                                                                         # AUGMENTATION\n",
    "\n",
    "    X_train,Y_train,recs_train_f=CNN_lib.shuffle(X_train_spl,Y_train_spl,recs_train)                                                                                                                       # SHUFFLE\n",
    "    \n",
    "    if checking_on: CNN_utilities.in_loop_check(check_record_2,recs_train_f,X_train,Y_train)                                                                                                                  # CHECK\n",
    "\n",
    "    hist=md.fit(X_train, Y_train, epochs=epochs, validation_data=(X_eval,Y_eval),callbacks=[chk_p])                                                                                                         # TRAIN\n",
    "    histories.append(hist)\n",
    "    \n",
    "    iter+=1\n",
    "    print(' ')\n",
    "    print(f'-------------- ITERATION {iter}/{trains_n} COMPLETED --------------')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos =[ load_model(pp) for pp in check_points_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0\n",
    "\n",
    "for history in histories: \n",
    "    \n",
    "    print(f'ITERATION: {ii}')\n",
    "    CNN_lib.plot_train_eval(history,epochs)\n",
    "    ii+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy= [],[]\n",
    "\n",
    "for model in modelos:\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_eval,Y_eval,verbose=0) \n",
    "\n",
    "    loss.append(test_loss)\n",
    "    accuracy.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_aucs = []\n",
    "\n",
    "for model in modelos:\n",
    "\n",
    "    predictions = model.predict(X_eval)\n",
    "\n",
    "    fpr_val, tpr_val, thresholds_val = roc_curve(Y_eval, predictions)\n",
    "    roc_auc_false = auc(fpr_val, tpr_val)\n",
    "    roc_aucs.append(roc_auc_false)\n",
    "\n",
    "    CNN_lib.plot_roc_curve(fpr_val,tpr_val,roc_auc_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_lib.list_plot(roc_aucs,title='AUCS',ylabel='Roc AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'AUC')\n",
    "CNN_lib.stats(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'LOSS')\n",
    "CNN_lib.stats(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'ACCURACITY')\n",
    "CNN_lib.stats(accuracy,rnd=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  FORECAST EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_raw=[]\n",
    "\n",
    "trsh=0.35\n",
    "\n",
    "for pred in predictions:\n",
    "\n",
    "    if pred < trsh:predictions_raw.append(0)\n",
    "    else:predictions_raw.append(1)\n",
    "\n",
    "predictions_raw=np.array(predictions_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(Y_eval, predictions_raw)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "classification_report_str = classification_report(Y_eval, predictions_raw)\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(classification_report_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = Y_eval  \n",
    "\n",
    "correctly_classified_indices = np.where(predictions_raw == true_classes)[0]\n",
    "incorrectly_classified_indices = np.where(predictions_raw != true_classes)[0]\n",
    "\n",
    "correctly_classified_video_ids = [video_id for video_id in correctly_classified_indices]\n",
    "incorrectly_classified_video_ids = [video_id for video_id in incorrectly_classified_indices]\n",
    "\n",
    "num_zeros = np.count_nonzero(Y_eval == 0)\n",
    "num_ones = np.count_nonzero(Y_eval == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels_val = [Y_eval[i] for i in correctly_classified_indices]\n",
    "\n",
    "print(correct_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"OK, {len(correctly_classified_video_ids)}\")\n",
    "print(f\"BAD, {len(incorrectly_classified_video_ids)}\")\n",
    "print(f'Ratio forecast: {len(correctly_classified_video_ids)/len(incorrectly_classified_video_ids)}')\n",
    "print(f'Ratio labeling: {max([num_ones,num_zeros])/min([num_ones,num_zeros])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
