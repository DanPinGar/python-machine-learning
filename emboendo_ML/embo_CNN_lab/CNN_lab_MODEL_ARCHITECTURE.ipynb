{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERNEL CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f -s\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import CNN_lib\n",
    "import CNN_utilities\n",
    "import fig_lib \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trains_n=15\n",
    "t_btw_frm=0.05\n",
    "\n",
    "checking_on=False\n",
    "data_augmentation= True\n",
    "\n",
    "checkpoint_path = \"C:/PROJECTS\\emboendo\\CNN\\python-machine-learning\\emboendo_ML\\embo_CNN_lab\\_static/checkpoints\"\n",
    "pkl_train_p='C:\\PROJECTS\\emboendo\\CNN/pikles/processed_train_d.pkl'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_points_p = [checkpoint_path+'_'+str(n)+'.h5' for n in range(trains_n)]\n",
    "\n",
    "check_points_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,Y_train\n",
    "\n",
    "with open(pkl_train_p, 'rb') as pikle_file:\n",
    "\n",
    "    save_trains= pickle.load(pikle_file)\n",
    "\n",
    "x_train,y_train,rcs =  save_trains[0],save_trains[1],save_trains[2]\n",
    "\n",
    "max_frm_n, HEIGHT, WIDTH=np.shape(x_train)[1],np.shape(x_train)[2],np.shape(x_train)[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on:\n",
    "\n",
    "    for x,y,r in zip(x_train,y_train,rcs):\n",
    "        print(r,int(y),np.shape(x),type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on:\n",
    "\n",
    "    rec_elm='I70'\n",
    "    idx=rcs.index(rec_elm)\n",
    "    print(y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on:fig_lib.vid_show(x_train[idx],t_btw_frm=t_btw_frm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xx_train=x_train\n",
    "Yy_train=y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SHUFFLE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx_train,Yy_train,recs=CNN_lib.shuffle(Xx_train,Yy_train,rcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.2\n",
    "\n",
    "X_train_spl, X_eval_spl, Y_train_spl, Y_eval_spl = train_test_split(Xx_train, Yy_train, test_size=test_size, shuffle=False) #,random_state=42)\n",
    "\n",
    "recs_train =recs[0:len(Y_train_spl)]\n",
    "recs_eval =recs[len(Y_train_spl)::]\n",
    "\n",
    "print('Train data:',len(Y_train_spl),'Evaluation data:',len(Y_eval_spl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "\n",
    "zeros_count = np.sum(Y_train_spl == 0)\n",
    "ones_count = np.sum(Y_train_spl == 1)\n",
    "zeros_count_val = np.sum(Y_eval_spl == 0)\n",
    "ones_count_val = np.sum(Y_eval_spl == 1)\n",
    "\n",
    "print(' Train data shape:', np.shape(X_train_spl),' Validation data shape:', np.shape(X_eval_spl))\n",
    "\n",
    "CNN_lib.data_bars_plot(zeros_count,ones_count,zeros_count_val,ones_count_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augmentation:\n",
    "    \n",
    "    n_flip_1=0.7\n",
    "    n_flip_0=0.07\n",
    "\n",
    "    nf1 = round(n_flip_1*ones_count)\n",
    "    nf0 = round(n_flip_0*zeros_count)\n",
    "\n",
    "    print(f'Flip 1: {nf1}, 0: {nf0}')\n",
    "\n",
    "    n_rot_1=0.7\n",
    "    n_rot_0=0.07\n",
    "\n",
    "    nr1 = round(n_rot_1*ones_count)\n",
    "    nr0 = round(n_rot_0*zeros_count)\n",
    "\n",
    "    print(f'Rotation 1: {nr1}, 0: {nr0}')\n",
    "\n",
    "    n_contr_1=0.4\n",
    "    n_contr_0=0.04\n",
    "\n",
    "    nc1 = round(n_contr_1*ones_count)\n",
    "    nc0 = round(n_contr_0*zeros_count)\n",
    "\n",
    "    print(f'Contrast 1: {nc1}, 0: {nc0}')\n",
    "\n",
    "    n_bright_1=0.4\n",
    "    n_bright_0=0.04\n",
    "\n",
    "    nb1 = round(n_bright_1*ones_count)\n",
    "    nb0 = round(n_bright_0*zeros_count)\n",
    "\n",
    "    print(f'brightness 1: {nb1}, 0: {nb0}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if data_augmentation:\n",
    "\n",
    "    Flip_X_1,Flip_Y_1,Flip_recs_1=CNN_lib.main_aug_f(nf1,X_train_spl,Y_train_spl,recs,label=1,typ='Flip')\n",
    "    Flip_X_0,Flip_Y_0,Flip_recs_0=CNN_lib.main_aug_f(nf0,X_train_spl,Y_train_spl,recs,label=0,typ='Flip')\n",
    "\n",
    "    Rot_X_1,Rot_Y_1,Rot_recs_1=CNN_lib.main_aug_f(nr1,X_train_spl,Y_train_spl,recs,label=1,typ='Rotation')\n",
    "    Rot_X_0,Rot_Y_0,Rot_recs_0=CNN_lib.main_aug_f(nr0,X_train_spl,Y_train_spl,recs,label=0,typ='Rotation')\n",
    "\n",
    "    Cntr_X_1,Cntr_Y_1,Cntr_recs_1=CNN_lib.main_aug_f(nc1,X_train_spl,Y_train_spl,recs,label=1,typ='Contrast')\n",
    "    Cntr_X_0,Cntr_Y_0,Cntr_recs_0=CNN_lib.main_aug_f(nc0,X_train_spl,Y_train_spl,recs,label=0,typ='Contrast')\n",
    "\n",
    "    Bgr_X_1,Bgr_Y_1,Bgr_recs_1=CNN_lib.main_aug_f(nb1,X_train_spl,Y_train_spl,recs,label=1,typ='Brightness')\n",
    "    Bgr_X_0,Bgr_Y_0,Bgr_recs_0=CNN_lib.main_aug_f(nb0,X_train_spl,Y_train_spl,recs,label=0,typ='Brightness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augmentation:\n",
    "\n",
    "    X_train_spl = np.concatenate((X_train_spl, Flip_X_1,Flip_X_0,Rot_X_1,Rot_X_0,Cntr_X_1,Cntr_X_0,Bgr_X_1,Bgr_X_0), axis=0)\n",
    "    Y_train_spl = np.concatenate((Y_train_spl, Flip_Y_1,Flip_Y_0,Rot_Y_1,Rot_Y_0,Cntr_Y_1,Cntr_Y_0,Bgr_Y_1,Bgr_Y_0))\n",
    "    \n",
    "    recs_train = recs_train+Flip_recs_1+Flip_recs_0+Rot_recs_1+Rot_recs_0+Cntr_recs_1+Cntr_recs_0+Bgr_recs_1+Bgr_recs_0\n",
    "\n",
    "    print(X_train_spl.shape,Y_train_spl.shape)\n",
    "    print(X_eval_spl.shape,Y_eval_spl.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA SHUFFLE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augmentation: X_train,Y_train,recs_train_f=CNN_lib.shuffle(X_train_spl,Y_train_spl,recs_train)\n",
    "else: X_train,Y_train,recs_train_f = X_train_spl,Y_train_spl,recs_train\n",
    "\n",
    "X_eval=X_eval_spl\n",
    "Y_eval=Y_eval_spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "if data_augmentation:\n",
    "\n",
    "    zeros_count = np.sum(Y_train == 0)\n",
    "    ones_count = np.sum(Y_train == 1)\n",
    "    zeros_count_val = np.sum(Y_eval == 0)\n",
    "    ones_count_val = np.sum(Y_eval == 1)\n",
    "\n",
    "    CNN_lib.data_bars_plot(zeros_count,ones_count,zeros_count_val,ones_count_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on:\n",
    "\n",
    "    for x,y,r in zip(X_train,Y_train,recs_train_f):\n",
    "        print(r,int(y),np.shape(x),type(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if checking_on:\n",
    "\n",
    "    rec_elm='I180'\n",
    "    idx=recs_train_f.index(rec_elm)\n",
    "    print(idx,Y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on:fig_lib.vid_show(X_train[idx],t_btw_frm=t_btw_frm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LIBRARY MODELS:')\n",
    "print(' ')\n",
    "\n",
    "for model_name in CNN_lib.MODELS.values(): print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CNN PARAMS --------\n",
    "\n",
    "# -------- MODEL --------\n",
    "\n",
    "model_from_CNN_lib,mdl= False,'video_conv3D'\n",
    "\n",
    "opt='adam'\n",
    "lss='binary_crossentropy'\n",
    "\n",
    "# -------- TRAINNING --------\n",
    "\n",
    "epochs=8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL \n",
    "input_shape=(max_frm_n, HEIGHT, WIDTH, 1)\n",
    "\n",
    "modelos=[]\n",
    "\n",
    "for _ in check_points_p:\n",
    "\n",
    "  if model_from_CNN_lib: model = CNN_lib.lib_models(mdl,im_input_shp=input_shape)\n",
    "\n",
    "  else:\n",
    "\n",
    "    model = models.Sequential([\n",
    "            layers.Conv3D(filters=16, kernel_size=(3, 3, 1), activation='relu',input_shape=input_shape),\n",
    "            layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "            layers.Conv3D(filters=32, kernel_size=(3, 3, 1),  activation='relu'),\n",
    "            layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "            layers.Conv3D(filters=32, kernel_size=(3, 3, 1),  activation='relu'),\n",
    "            layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "            layers.Conv3D(filters=16, kernel_size=(1, 1, 5),  activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1,activation='sigmoid')\n",
    "            ])\n",
    "    \n",
    "  model.compile(optimizer=opt, loss=lss, metrics=['accuracy'])\n",
    "  modelos.append(model)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints=[ModelCheckpoint(pp, save_best_only=True, monitor='val_loss',   mode='min', verbose=1) for pp in check_points_p]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories=[md.fit(X_train, Y_train, epochs=epochs, validation_data=(X_eval,Y_eval),callbacks=[chk_p]) for md, chk_p in zip(modelos,checkpoints)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for history in histories: CNN_lib.plot_train_eval(history,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos =[ load_model(pp) for pp in check_points_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss= []\n",
    "accuracy = []\n",
    "\n",
    "for model in modelos:\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_eval,Y_eval,verbose=0) \n",
    "\n",
    "    loss.append(test_loss)\n",
    "    accuracy.append(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_aucs = []\n",
    "\n",
    "for model in modelos:\n",
    "\n",
    "    predictions = model.predict(X_eval)\n",
    "\n",
    "    fpr_val, tpr_val, thresholds_val = roc_curve(Y_eval, predictions)\n",
    "    roc_auc_false = auc(fpr_val, tpr_val)\n",
    "    roc_aucs.append(roc_auc_false)\n",
    "\n",
    "    #CNN_lib.plot_roc_curve(fpr_val,tpr_val,roc_auc_false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_lib.list_plot(roc_aucs,title='AUCS',ylabel='Roc AUC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'AUC')\n",
    "\n",
    "CNN_lib.stats(roc_aucs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'LOSS')\n",
    "\n",
    "CNN_lib.stats(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'ACCURACITY')\n",
    "\n",
    "CNN_lib.stats(accuracy,rnd=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  FORECAST EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_raw=[]\n",
    "\n",
    "trsh=0.35\n",
    "\n",
    "for pred in predictions:\n",
    "\n",
    "    if pred < trsh:predictions_raw.append(0)\n",
    "    else:predictions_raw.append(1)\n",
    "\n",
    "predictions_raw=np.array(predictions_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(Y_eval, predictions_raw)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Obtener el informe de clasificación\n",
    "classification_report_str = classification_report(Y_eval, predictions_raw)\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(classification_report_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = Y_eval  \n",
    "\n",
    "correctly_classified_indices = np.where(predictions_raw == true_classes)[0]\n",
    "incorrectly_classified_indices = np.where(predictions_raw != true_classes)[0]\n",
    "\n",
    "correctly_classified_video_ids = [video_id for video_id in correctly_classified_indices]\n",
    "incorrectly_classified_video_ids = [video_id for video_id in incorrectly_classified_indices]\n",
    "\n",
    "num_zeros = np.count_nonzero(Y_eval == 0)\n",
    "num_ones = np.count_nonzero(Y_eval == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels_val = [Y_eval[i] for i in correctly_classified_indices]\n",
    "\n",
    "print(correct_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"OK, {len(correctly_classified_video_ids)}\")\n",
    "print(f\"BAD, {len(incorrectly_classified_video_ids)}\")\n",
    "print(f'Ratio forecast: {len(correctly_classified_video_ids)/len(incorrectly_classified_video_ids)}')\n",
    "print(f'Ratio labeling: {max([num_ones,num_zeros])/min([num_ones,num_zeros])}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
