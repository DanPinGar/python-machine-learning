{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_lib\n",
    "import CNN_utilities\n",
    "import fig_lib \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_on=False\n",
    "\n",
    "check_record_1= '670615_19'\n",
    "check_record_2= 'ROT_670615_19'\n",
    "t_btw_frm=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_models_d_p = 'C:\\PROJECTS\\EMBOENDO\\CNN\\python-machine-learning\\emboendo_ML\\embo_CNN_lab\\_static/models.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_models_d_p, 'rb') as pikle_file:\n",
    "\n",
    "    models_d= pickle.load(pikle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_0': {'path': 'C:/PROJECTS\\\\emboendo\\\\CNN\\\\python-machine-learning\\\\emboendo_ML\\\\embo_CNN_lab\\\\_static/MODEL_ARCHITECTURE_CHECKPOINTS/chP_0.h5',\n",
       "  'name': 'MODEL 0',\n",
       "  'model': <keras.src.engine.sequential.Sequential at 0x2c864f10bd0>,\n",
       "  'check_point': <keras.src.callbacks.ModelCheckpoint at 0x2c875cc34d0>,\n",
       "  'history': <keras.src.callbacks.History at 0x2c864f2c710>,\n",
       "  'AUC': 0.6018808777429467},\n",
       " 'model_1': {'path': 'C:/PROJECTS\\\\emboendo\\\\CNN\\\\python-machine-learning\\\\emboendo_ML\\\\embo_CNN_lab\\\\_static/MODEL_ARCHITECTURE_CHECKPOINTS/chP_1.h5',\n",
       "  'name': 'MODEL 1',\n",
       "  'model': <keras.src.engine.sequential.Sequential at 0x2c866792050>,\n",
       "  'check_point': <keras.src.callbacks.ModelCheckpoint at 0x2c864f43b90>,\n",
       "  'history': <keras.src.callbacks.History at 0x2c864f41c90>,\n",
       "  'AUC': 0.36920933472657613}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA INPUT CHECK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on:\n",
    "\n",
    "    for x,y,r in zip(x_train,y_train,rcs):print(r,int(y),np.shape(x),type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checking_on: CNN_utilities.simple_check(check_record_1,rcs,x_train,y_train,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  FORECAST EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_raw=[]\n",
    "\n",
    "trsh=0.35\n",
    "\n",
    "for pred in predictions:\n",
    "\n",
    "    if pred < trsh:predictions_raw.append(0)\n",
    "    else:predictions_raw.append(1)\n",
    "\n",
    "predictions_raw=np.array(predictions_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusi贸n:\n",
      "[[ 0 87]\n",
      " [ 0 39]]\n",
      "Informe de Clasificaci贸n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        87\n",
      "           1       0.31      1.00      0.47        39\n",
      "\n",
      "    accuracy                           0.31       126\n",
      "   macro avg       0.15      0.50      0.24       126\n",
      "weighted avg       0.10      0.31      0.15       126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PROJECTS\\EMBOENDO\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\PROJECTS\\EMBOENDO\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\PROJECTS\\EMBOENDO\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(Y_eval, predictions_raw)\n",
    "\n",
    "print(\"Matriz de Confusi贸n:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "classification_report_str = classification_report(Y_eval, predictions_raw)\n",
    "print(\"Informe de Clasificaci贸n:\")\n",
    "print(classification_report_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = Y_eval  \n",
    "\n",
    "correct_idx = np.where(predictions_raw == true_classes)[0]\n",
    "incorrect_idx = np.where(predictions_raw != true_classes)[0]\n",
    "\n",
    "correct_vd_idx = [video_id for video_id in correct_idx]\n",
    "incorrect_vd_idx = [video_id for video_id in incorrect_idx]\n",
    "\n",
    "num_zeros = np.count_nonzero(Y_eval == 0)\n",
    "num_ones = np.count_nonzero(Y_eval == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "correct_labels_val = [Y_eval[i] for i in correct_idx]\n",
    "\n",
    "print(correct_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK, 39\n",
      "BAD, 87\n",
      "Ratio forecast: 0.4482758620689655\n",
      "Ratio labeling: 2.230769230769231\n"
     ]
    }
   ],
   "source": [
    "print(f\"OK, {len(correct_vd_idx)}\")\n",
    "print(f\"BAD, {len(incorrect_vd_idx)}\")\n",
    "print(f'Ratio forecast: {len(correct_vd_idx)/len(incorrect_vd_idx)}')\n",
    "print(f'Ratio labeling: {max([num_ones,num_zeros])/min([num_ones,num_zeros])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
