{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_lib\n",
    "import CNN_utilities\n",
    "import fig_lib \n",
    "import CNN_machine\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"C:/PROJECTS\\emboendo\\CNN\\python-machine-learning\\emboendo_ML\\embo_CNN_lab\\_static/checkpoints.h5\"\n",
    "pkl_train_p='C:\\PROJECTS\\emboendo\\CNN/pikles/processed_train_d.pkl'  \n",
    "\n",
    "number_data_ls= [i for i in range(70, 530, 51)]\n",
    "#number_data_ls= [i for i in range(70, 530, 400)]\n",
    "check_points_p = [checkpoint_path+'_'+str(n)+'.h5' for n in number_data_ls]\n",
    "models_perf_d={'model'+'_'+str(n):{} for n in number_data_ls}\n",
    "\n",
    "test_size=0.2\n",
    "epochs=8\n",
    "\n",
    "print(len(number_data_ls),number_data_ls)\n",
    "print(models_perf_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_train_p, 'rb') as pikle_file:\n",
    "    save_trains= pickle.load(pikle_file)\n",
    "\n",
    "Xx_train,Yy_train,rcs =  save_trains[0],save_trains[1],save_trains[2]\n",
    "max_frm_n, HEIGHT, WIDTH=np.shape(Xx_train)[1],np.shape(Xx_train)[2],np.shape(Xx_train)[3]\n",
    "input_shape=(max_frm_n, HEIGHT, WIDTH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN DATA SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx_train,Yy_train,recs=CNN_lib.shuffle(Xx_train,Yy_train,rcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.2\n",
    "X_train_spl, X_eval_spl, Y_train_spl, Y_eval_spl = train_test_split(Xx_train, Yy_train, test_size=test_size, shuffle=False) #,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "\n",
    "zeros_count = np.sum(Y_train_spl == 0)\n",
    "ones_count = np.sum(Y_train_spl == 1)\n",
    "zeros_count_val = np.sum(Y_eval_spl == 0)\n",
    "ones_count_val = np.sum(Y_eval_spl == 1)\n",
    "\n",
    "labels = ['0 Train', '1 Train','0 Validation', '1 Validation']\n",
    "print(' Train data shape:', np.shape(X_train_spl),' Validation data shape:', np.shape(X_eval_spl))\n",
    "\n",
    "plt.bar(labels, [zeros_count, ones_count,zeros_count_val,ones_count_val], color=['green', 'blue','green', 'blue'])\n",
    "\n",
    "for i, count in enumerate([zeros_count, ones_count,zeros_count_val,ones_count_val]):\n",
    "\n",
    "    plt.text(i, count + 0.1, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Data Labels Before Augmentation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[CNN_machine.Gen_Model(input_shape,pp,nn) for nn,pp in zip(number_data_ls,check_points_p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in models:\n",
    "\n",
    "    mdl.train_model(X_train_spl,Y_train_spl,X_eval_spl,Y_eval_spl, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mdl in models:CNN_lib.plot_train_eval(mdl.history,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in models: CNN_lib.plot_roc_curve(mdl.fpr_val,mdl.tpr_val,mdl.roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_ls=[mdl.roc_auc for mdl in models]\n",
    "number_points=[mdl.tr_pnt for mdl in models]\n",
    "\n",
    "plt.plot(number_points, AUC_ls, marker='o', linestyle='-', color='b', label='AUC')\n",
    "plt.xlabel('Número de Puntos')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('AUC en función del Número de Puntos')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
