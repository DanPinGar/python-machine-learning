{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\PROJECTS\\EMBOENDO\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\PROJECTS\\EMBOENDO\\CNN\\python-machine-learning\\emboendo_ML\\embo_CNN_lab\\CNN_machine.py:2: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import CNN_lib\n",
    "import CNN_utilities\n",
    "import fig_lib \n",
    "import CNN_machine\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 [48, 80, 112, 144, 176, 208, 240, 272, 304, 336, 368, 400, 432, 464, 496, 528]\n",
      "{'model_48': {}, 'model_80': {}, 'model_112': {}, 'model_144': {}, 'model_176': {}, 'model_208': {}, 'model_240': {}, 'model_272': {}, 'model_304': {}, 'model_336': {}, 'model_368': {}, 'model_400': {}, 'model_432': {}, 'model_464': {}, 'model_496': {}, 'model_528': {}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint_path = \"C:/PROJECTS\\emboendo\\CNN\\python-machine-learning\\emboendo_ML\\embo_CNN_lab\\_static/checkpoints\"\n",
    "pkl_train_p='C:\\PROJECTS\\emboendo\\CNN/pikles/processed_train_d.pkl'  \n",
    "\n",
    "number_data_ls= [i for i in range(48, 530, 32)]\n",
    "check_points_p = [checkpoint_path+'_'+str(n)+'.h5' for n in number_data_ls]\n",
    "models_perf_d={'model'+'_'+str(n):{} for n in number_data_ls}\n",
    "\n",
    "test_size=0.2\n",
    "epochs=7\n",
    "\n",
    "print(len(number_data_ls),number_data_ls)\n",
    "print(models_perf_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_train_p, 'rb') as pikle_file:\n",
    "    save_trains= pickle.load(pikle_file)\n",
    "\n",
    "Xx_train,Yy_train,rcs =  save_trains[0],save_trains[1],save_trains[2]\n",
    "max_frm_n, HEIGHT, WIDTH=np.shape(Xx_train)[1],np.shape(Xx_train)[2],np.shape(Xx_train)[3]\n",
    "input_shape=(max_frm_n, HEIGHT, WIDTH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN DATA SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx_train,Yy_train,recs=CNN_lib.shuffle(Xx_train,Yy_train,rcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.2\n",
    "X_train_spl, X_eval_spl, Y_train_spl, Y_eval_spl = train_test_split(Xx_train, Yy_train, test_size=test_size, shuffle=False) #,random_state=42)\n",
    "\n",
    "recs_train =recs[0:len(Y_train_spl)]\n",
    "recs_eval =recs[len(Y_train_spl)::]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 48 ,Flip 0: 2 ,Flip 1: 15 ,Contr 0: 1 ,Contr 1: 6 ,Bright 0: 1 ,Bright 1: 6\n",
      "Samples: 80 ,Flip 0: 4 ,Flip 1: 28 ,Contr 0: 2 ,Contr 1: 11 ,Bright 0: 2 ,Bright 1: 11\n",
      "Samples: 112 ,Flip 0: 6 ,Flip 1: 32 ,Contr 0: 2 ,Contr 1: 13 ,Bright 0: 3 ,Bright 1: 13\n",
      "Samples: 144 ,Flip 0: 7 ,Flip 1: 37 ,Contr 0: 3 ,Contr 1: 15 ,Bright 0: 4 ,Bright 1: 15\n",
      "Samples: 176 ,Flip 0: 9 ,Flip 1: 46 ,Contr 0: 4 ,Contr 1: 18 ,Bright 0: 5 ,Bright 1: 18\n",
      "Samples: 208 ,Flip 0: 11 ,Flip 1: 53 ,Contr 0: 5 ,Contr 1: 21 ,Bright 0: 6 ,Bright 1: 21\n",
      "Samples: 240 ,Flip 0: 13 ,Flip 1: 61 ,Contr 0: 5 ,Contr 1: 24 ,Bright 0: 7 ,Bright 1: 24\n",
      "Samples: 272 ,Flip 0: 14 ,Flip 1: 68 ,Contr 0: 6 ,Contr 1: 27 ,Bright 0: 8 ,Bright 1: 27\n",
      "Samples: 304 ,Flip 0: 16 ,Flip 1: 78 ,Contr 0: 7 ,Contr 1: 31 ,Bright 0: 9 ,Bright 1: 31\n",
      "Samples: 336 ,Flip 0: 17 ,Flip 1: 89 ,Contr 0: 7 ,Contr 1: 36 ,Bright 0: 10 ,Bright 1: 36\n",
      "Samples: 368 ,Flip 0: 19 ,Flip 1: 101 ,Contr 0: 8 ,Contr 1: 40 ,Bright 0: 11 ,Bright 1: 40\n",
      "Samples: 400 ,Flip 0: 20 ,Flip 1: 108 ,Contr 0: 9 ,Contr 1: 43 ,Bright 0: 12 ,Bright 1: 43\n",
      "Samples: 432 ,Flip 0: 22 ,Flip 1: 116 ,Contr 0: 9 ,Contr 1: 46 ,Bright 0: 13 ,Bright 1: 46\n",
      "Samples: 464 ,Flip 0: 24 ,Flip 1: 122 ,Contr 0: 10 ,Contr 1: 49 ,Bright 0: 14 ,Bright 1: 49\n",
      "Samples: 496 ,Flip 0: 26 ,Flip 1: 130 ,Contr 0: 11 ,Contr 1: 52 ,Bright 0: 15 ,Bright 1: 52\n",
      "Samples: 528 ,Flip 0: 27 ,Flip 1: 138 ,Contr 0: 12 ,Contr 1: 55 ,Bright 0: 16 ,Bright 1: 55\n"
     ]
    }
   ],
   "source": [
    "nf1_ls,nf0_ls,nc1_ls,nc0_ls,nb1_ls,nb0_ls= [],[],[],[],[],[]\n",
    "\n",
    "for nn in number_data_ls:\n",
    "\n",
    "    zeros_count = np.sum(Y_train_spl[0:nn] == 0)\n",
    "    ones_count= np.sum(Y_train_spl[0:nn] == 1)\n",
    "\n",
    "    n_flip_1=1\n",
    "    n_flip_0=0.07\n",
    "\n",
    "    nf1_ls.append(round(n_flip_1*ones_count))\n",
    "    nf0_ls.append(round(n_flip_0*zeros_count))\n",
    "\n",
    "    n_contr_1=0.4\n",
    "    n_contr_0=0.03\n",
    "\n",
    "    nc1_ls.append(round(n_contr_1*ones_count))\n",
    "    nc0_ls.append(round(n_contr_0*zeros_count))\n",
    "\n",
    "    n_bright_1=0.4\n",
    "    n_bright_0=0.04\n",
    "\n",
    "    nb1_ls.append(round(n_bright_1*ones_count))\n",
    "    nb0_ls.append(round(n_bright_0*zeros_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , Y_train = [] , []\n",
    "\n",
    "for nn,nf1,nf0,nc1,nc0,nb1,nb0 in zip(number_data_ls,nf1_ls,nf0_ls,nc1_ls,nc0_ls,nb1_ls,nb0_ls):\n",
    "\n",
    "    print('Samples:',nn,',Flip 0:',nf0, ',Flip 1:',nf1,',Contr 0:',nc0,',Contr 1:',nc1,',Bright 0:',nb0,',Bright 1:',nb1)\n",
    "\n",
    "    \n",
    "    Flip_X_1,Flip_Y_1,Flip_recs_1=CNN_lib.main_aug_f(nf1,X_train_spl[0:nn],Y_train_spl[0:nn],recs[0:nn],label=1,typ='Flip')\n",
    "    Flip_X_0,Flip_Y_0,Flip_recs_0=CNN_lib.main_aug_f(nf0,X_train_spl[0:nn],Y_train_spl[0:nn],recs[0:nn],label=0,typ='Flip')\n",
    "\n",
    "    Cntr_X_1,Cntr_Y_1,Cntr_recs_1=CNN_lib.main_aug_f(nc1,X_train_spl[0:nn],Y_train_spl[0:nn],recs[0:nn],label=1,typ='Contrast')\n",
    "    Cntr_X_0,Cntr_Y_0,Cntr_recs_0=CNN_lib.main_aug_f(nc0,X_train_spl[0:nn],Y_train_spl[0:nn],recs[0:nn],label=0,typ='Contrast')\n",
    "\n",
    "    Bgr_X_1,Bgr_Y_1,Bgr_recs_1=CNN_lib.main_aug_f(nb1,X_train_spl[0:nn],Y_train_spl[0:nn],recs[0:nn],label=1,typ='Brightness')\n",
    "    Bgr_X_0,Bgr_Y_0,Bgr_recs_0=CNN_lib.main_aug_f(nb0,X_train_spl[0:nn],Y_train_spl[0:nn],recs[0:nn],label=0,typ='Brightness')\n",
    "\n",
    "    X_train_n = np.concatenate((X_train_spl[0:nn], Flip_X_1,Flip_X_0,Cntr_X_1,Cntr_X_0,Bgr_X_1,Bgr_X_0), axis=0)\n",
    "    Y_train_n = np.concatenate((Y_train_spl[0:nn], Flip_Y_1, Flip_Y_0,Cntr_Y_1,Cntr_Y_0,Bgr_Y_1,Bgr_Y_0))\n",
    "    \n",
    "    recs_n = recs_train[0:nn]+Flip_recs_1+Flip_recs_0+Cntr_recs_1+Cntr_recs_0+Bgr_recs_1+Bgr_recs_0\n",
    "\n",
    "    X_train.append(X_train_n)\n",
    "    Y_train.append(Y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for xx, yy,nn in zip(X_train , Y_train,number_data_ls): print('Data:',nn,'X train shape:',xx.shape, 'Y train shape:',yy.shape )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[CNN_machine.Gen_Model(input_shape,pp) for pp in check_points_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=1\n",
    "print(' ')\n",
    "for mdl,X,Y in zip(models,X_train,Y_train):\n",
    "    \n",
    "    print(f'-----------------{ii}-----------------')\n",
    "    mdl.train_model(X,Y,X_eval_spl,Y_eval_spl, epochs)\n",
    "    print('-----------------------------------')\n",
    "    print(' ')\n",
    "    ii+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mdl in models:CNN_lib.plot_train_eval(mdl.history,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in models: CNN_lib.plot_roc_curve(mdl.fpr_val,mdl.tpr_val,mdl.roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_ls=[mdl.roc_auc for mdl in models]\n",
    "number_points=[mdl.tr_pnt for mdl in models]\n",
    "\n",
    "plt.plot(number_points, AUC_ls, marker='o', linestyle='-', color='b', label='AUC')\n",
    "plt.xlabel('SAMPLES')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('AUC VS SAMPLES')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
