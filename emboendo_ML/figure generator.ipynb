{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_vd(input,rec,n_frames,height=100, width=100):\n",
    "\n",
    "    x1=np.random.randint(0, width-1)\n",
    "    x2=np.random.randint(0, width-1)\n",
    "    y1=np.random.randint(0, height-1)\n",
    "    y2=np.random.randint(0, height-1)\n",
    "    thickness=np.random.randint(1, 3)\n",
    "    \n",
    "    vd_ls=[]\n",
    "\n",
    "    for _ in range(n_frames):\n",
    "        \n",
    "        image = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        x1+= np.random.randint(-int(width*0.02), int(width*0.02))\n",
    "        x2+=np.random.randint(-int(width*0.06), int(width*0.06))\n",
    "        y1+= np.random.randint(-int(height*0.02), int(height*0.02))\n",
    "        y2+=np.random.randint(-int(height*0.06), int(height*0.06))\n",
    "        \n",
    "        cv2.line(image, (x1, y1), (x2, y2), color=255, thickness=thickness)\n",
    "        vd_ls.append(image)\n",
    "\n",
    "    input[rec]['vd_d']=np.array(vd_ls)\n",
    "    input[rec]['label']=0\n",
    "\n",
    "    return input\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIRCLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_vd(input,rec,n_frames,height=100, width=100):\n",
    "    \n",
    "    thickness=np.random.randint(1, 2)\n",
    "    x= np.random.randint(int(0+width*0.3), int(width - width*0.3))\n",
    "    y=np.random.randint(int(0+height*0.3), int(height-height*0.3))\n",
    "    radio = np.random.randint(12, 17)\n",
    "    vd_ls=[]\n",
    "\n",
    "    for _ in range(n_frames):\n",
    "        \n",
    "        image = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        x+= np.random.randint(-int(width*0.03), int(width*0.03))\n",
    "        y+= np.random.randint(-int(height*0.03), int(height*0.03))\n",
    "        radio += np.random.randint(-int(height*0.01), int(height*0.02))\n",
    "        \n",
    "        cv2.circle(image, (x,y), radio, color=255, thickness=thickness)\n",
    "        vd_ls.append(image)\n",
    "\n",
    "    input[rec]['vd_d']=np.array(vd_ls)\n",
    "    input[rec]['label']=1\n",
    "\n",
    "    return input\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, wide = 100, 100\n",
    "n_recs=30\n",
    "min_frm,max_frm=5,10\n",
    "\n",
    "input_d={'I'+ str(ii):{} for ii in range(n_recs)}\n",
    "\n",
    "for R in input_d.keys():\n",
    "\n",
    "    n_frames=np.random.randint(min_frm,max_frm)\n",
    "    input_c=input_d.copy()\n",
    "    n_rdm=np.random.rand()\n",
    "\n",
    "    if n_rdm>=0.5:input_d=line_vd(input_c,R,n_frames,height, wide)\n",
    "    else:input_d=circle_vd(input_c,R,n_frames,height, wide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECORD - LABEL - SHAPE\n",
      "I0 0 (8, 100, 100) <class 'numpy.ndarray'>\n",
      "I1 1 (7, 100, 100) <class 'numpy.ndarray'>\n",
      "I2 0 (7, 100, 100) <class 'numpy.ndarray'>\n",
      "I3 0 (8, 100, 100) <class 'numpy.ndarray'>\n",
      "I4 1 (9, 100, 100) <class 'numpy.ndarray'>\n",
      "I5 0 (5, 100, 100) <class 'numpy.ndarray'>\n",
      "I6 0 (7, 100, 100) <class 'numpy.ndarray'>\n",
      "I7 0 (6, 100, 100) <class 'numpy.ndarray'>\n",
      "I8 0 (8, 100, 100) <class 'numpy.ndarray'>\n",
      "I9 1 (9, 100, 100) <class 'numpy.ndarray'>\n",
      "I10 0 (6, 100, 100) <class 'numpy.ndarray'>\n",
      "I11 1 (9, 100, 100) <class 'numpy.ndarray'>\n",
      "I12 1 (6, 100, 100) <class 'numpy.ndarray'>\n",
      "I13 1 (9, 100, 100) <class 'numpy.ndarray'>\n",
      "I14 1 (9, 100, 100) <class 'numpy.ndarray'>\n",
      "I15 1 (7, 100, 100) <class 'numpy.ndarray'>\n",
      "I16 0 (8, 100, 100) <class 'numpy.ndarray'>\n",
      "I17 1 (9, 100, 100) <class 'numpy.ndarray'>\n",
      "I18 0 (8, 100, 100) <class 'numpy.ndarray'>\n",
      "I19 1 (5, 100, 100) <class 'numpy.ndarray'>\n",
      "I20 0 (8, 100, 100) <class 'numpy.ndarray'>\n",
      "I21 0 (9, 100, 100) <class 'numpy.ndarray'>\n",
      "I22 1 (8, 100, 100) <class 'numpy.ndarray'>\n",
      "I23 1 (7, 100, 100) <class 'numpy.ndarray'>\n",
      "I24 1 (6, 100, 100) <class 'numpy.ndarray'>\n",
      "I25 1 (7, 100, 100) <class 'numpy.ndarray'>\n",
      "I26 1 (5, 100, 100) <class 'numpy.ndarray'>\n",
      "I27 0 (7, 100, 100) <class 'numpy.ndarray'>\n",
      "I28 1 (9, 100, 100) <class 'numpy.ndarray'>\n",
      "I29 1 (8, 100, 100) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('RECORD - LABEL - SHAPE')\n",
    "for R in input_d.keys():\n",
    "    print(R,input_d[R]['label'],np.shape(input_d[R]['vd_d']),type(input_d[R]['vd_d']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_check,rec_check=True,'I0'\n",
    "\n",
    "if video_check:\n",
    "    \n",
    "    t_btw_frm=0.2\n",
    "\n",
    "    for ii in range(len(input_d[rec_check]['vd_d'])):\n",
    "\n",
    "        imagen = input_d[rec_check]['vd_d'][ii]\n",
    "\n",
    "        plt.imshow(imagen, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        time.sleep(t_btw_frm)\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_frm_n=max([len(input_d[R]['vd_d']) for R in input_d.keys()])\n",
    "x_train,y_train=[],[]\n",
    "\n",
    "for R in input_d.keys():\n",
    "\n",
    "    vd=input_d[R]['vd_d']\n",
    "    vd = vd[:, :, :, np.newaxis]\n",
    "    x_train.append(vd)\n",
    "    y_train.append(input_d[R]['label'])\n",
    "\n",
    "for i, video in enumerate(x_train):\n",
    "    frames_actual = video.shape[0]\n",
    "    if frames_actual < max_frm_n:\n",
    "        \n",
    "        padding = np.zeros((max_frm_n - frames_actual, height, wide, 1))\n",
    "        x_train[i] = np.concatenate([video, padding], axis=0)\n",
    "    elif frames_actual > max_frm_n:\n",
    "        \n",
    "        x_train[i] = video[:max_frm_n, :, :, :]\n",
    "\n",
    "X_train = np.array(x_train)\n",
    "Y_train = np.array(y_train)\n",
    "\n",
    "#X_train, Y_train = X_train / 255.0, Y_train / 255.0\n",
    "\n",
    "for ii in range(len(input_d.keys())): print(np.shape(X_train[ii]),Y_train[ii])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(16, (3, 3), activation='relu'), input_shape=(max_frm_n, height, wide, 1)))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "\n",
    "# Capa LSTM\n",
    "model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "model.add(layers.LSTM(16))\n",
    "\n",
    "# Capa densa de salida\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "verification_input_d={'LINE':{}, 'CIRCLE':{}}\n",
    "n_frames=np.random.randint(min_frm,max_frm)\n",
    "\n",
    "verification_input_c=verification_input_d.copy()\n",
    "verification_input_d=line_vd(verification_input_c,'LINE',n_frames,height, wide)\n",
    "\n",
    "verification_input_c=verification_input_d.copy()\n",
    "verification_input_d=circle_vd(verification_input_c,'CIRCLE',n_frames,height, wide)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('RECORD - LABEL - SHAPE')\n",
    "for R in verification_input_d.keys():\n",
    "    print(R,verification_input_d[R]['label'],np.shape(verification_input_d[R]['vd_d']),type(verification_input_d[R]['vd_d']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_btw_frm=0.2\n",
    "\n",
    "for ii in range(len(verification_input_d['LINE']['vd_d'])):\n",
    "    \n",
    "    im_line = verification_input_d['LINE']['vd_d'][ii]\n",
    "    im_circle = verification_input_d['CIRCLE']['vd_d'][ii]\n",
    "    fig, axs = plt.subplots(1, 2)#, figsize=(10, 5))\n",
    "\n",
    "    axs[0].imshow(im_line , cmap='gray')\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(im_circle, cmap='gray')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    time.sleep(t_btw_frm)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_line=verification_input_d['LINE']['vd_d']\n",
    "vd_line = vd_line[:, :, :, np.newaxis]\n",
    "\n",
    "if vd_line.shape[0] < max_frm_n:\n",
    "    \n",
    "    padding = np.zeros((max_frm_n - vd_line.shape[0],  height, wide, 1))\n",
    "    vd_line = np.concatenate([vd_line, padding], axis=0)\n",
    "\n",
    "vd_circle=verification_input_d['CIRCLE']['vd_d']\n",
    "vd_circle = vd_circle[:, :, :, np.newaxis]\n",
    "\n",
    "if vd_circle.shape[0] < max_frm_n:\n",
    "    \n",
    "    padding = np.zeros((max_frm_n - vd_circle.shape[0],  height, wide, 1))\n",
    "    vd_circle = np.concatenate([vd_circle, padding], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_line = model.predict(np.expand_dims(vd_line, axis=0))\n",
    "pred_line_r=np.round(pred_line[0][0], decimals=4)\n",
    "\n",
    "pred_circle = model.predict(np.expand_dims(vd_circle, axis=0))\n",
    "pred_circle_r=np.round(pred_circle[0][0], decimals=4)\n",
    "\n",
    "print('VIDEO LÍNEA:')\n",
    "if pred_line >=0.5: print(f'Es {pred_line_r*100} % CÍRCULO')\n",
    "else:print(f'Es {(1-pred_line_r)*100} % LÍNEA')\n",
    "print(' ')\n",
    "\n",
    "print('VIDEO CÍRCULO:')\n",
    "if pred_circle >=0.5: print(f'Es {(pred_circle_r)*100} % CÍRCULO')\n",
    "else:print(f'Es {(1-pred_circle_r)*100} % LÍNEA')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
